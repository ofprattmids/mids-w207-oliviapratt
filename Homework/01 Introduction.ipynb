{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHLcriKWLRe4"
   },
   "source": [
    "# Lab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7X58hOMTUH-w"
   },
   "outputs": [],
   "source": [
    "# Import the libraries we'll use below.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nNOD-Z7SzAq"
   },
   "source": [
    "## Data as matrices\n",
    "Data usually comes in the form of matrices. The Python Numpy library makes it easy to manipulate matrices efficiently. See the [Numpy Tutorial](https://docs.scipy.org/doc/numpy/user/quickstart.html) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KWlmuAMwTZ3P"
   },
   "outputs": [],
   "source": [
    "# Print these to make sure you understand what is being generated.\n",
    "A = np.array([1, 2, 3])\n",
    "B = np.arange(1, 13).reshape(3, 4)\n",
    "C = np.ones((2, 3))\n",
    "D = np.eye(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4wvvzKoUIAN"
   },
   "source": [
    "---\n",
    "### Exercise 1: Matrix manipulation (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the following computations using numpy functions and print the results. Note that the `*` operator implies matrix multiplication -- make sure the dimensions align!\n",
    "1. 2A + 1\n",
    "2. Sum the rows of B\n",
    "3. Sum the columns of B\n",
    "4. Number of elements of B greater than 5\n",
    "5. C + C\n",
    "6. A * B\n",
    "7. (B * B) - D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HJtwrjdO6TbS"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbCRG2-uUKCT"
   },
   "source": [
    "## Data for Supervised Learning\n",
    "Supervised learning is all about learning to make predictions: given an input $x$ (e.g. home square footage), can we produce an output $\\hat{y}$ (e.g. estimated value) as close to the actual observed output $y$ (e.g. sale price) as possible. Note that the \"hat\" above $y$ is used to denote an estimated or predicted value.\n",
    "\n",
    "Let's start by generating some artificial data. We'll create a vector of inputs, $X$, and a corresponding vector of target outputs $Y$. In general, we'll refer to invidual examples with a lowercase ($x$), and a vector or matrix containing multiple examples with a capital ($X$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ulmn_bFdU87t"
   },
   "outputs": [],
   "source": [
    "def create_1d_data(num_examples=10, w=2, b=1, random_scale=1):\n",
    "  \"\"\"Create X, Y data with a linear relationship with added noise.\n",
    "\n",
    "  Args:\n",
    "    num_examples: number of examples to generate\n",
    "    w: desired slope\n",
    "    b: desired intercept\n",
    "    random_scale: add uniform noise between -random_scale and +random_scale\n",
    "\n",
    "  Returns:\n",
    "    X and Y with shape (num_examples)\n",
    "  \"\"\"\n",
    "  X = np.arange(num_examples)\n",
    "  np.random.seed(4)  # consistent random number generation\n",
    "  deltas = np.random.uniform(low=-random_scale, high=random_scale, size=X.shape)\n",
    "  Y = b + deltas + w * X\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6qJg0IiYVJ8U"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create some artificial data using create_1d_data.\n",
    "X, Y = create_1d_data()\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6coKbXSpXOz"
   },
   "source": [
    "---\n",
    "### Exercise 2: Models for Data (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model is a function that takes an input $x$ and produces a prediction $\\hat{y}$.\n",
    "\n",
    "Let's consider two possible models for this data:\n",
    "1. $M_1(x) = x+5$ \n",
    "2. $M_2(x) = 2x+1$\n",
    "\n",
    "Compute the predictions of models $M_1$ and $M_2$ for the values in $X$. These predictions should be vectors of the same shape as $Y$. Then plot the prediction lines of these two models overlayed on the \"observed\" data $(X, Y)$. Use [plt.plot()](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html) to draw the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHIY5kNXUIAP"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NH-0soZiWx9x"
   },
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "How good are our models? Intuitively, the better the model, the more closely it fits the data we have. That is, for each $x$, we'll compare $y$, the true value, with $\\hat{y}$, the predicted value. This comparison is often called the *loss* or the *error*. One common such comparison is *squared error*: $(y-\\hat{y})^2$. Averaging over all our data points, we get the *mean squared error*:\n",
    "\n",
    "\\begin{equation}\n",
    "\\textit{MSE} = \\frac{1}{|Y|} \\sum_{y_i \\in Y}(y_i - \\hat{y}_i)^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AyY2DpxYLI0"
   },
   "source": [
    "---\n",
    "### Exercise 3: Computing MSE (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function for computing the MSE metric and use it to compute the MSE for the two models above, $M_1$ and $M_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCeAfI5mW9sg"
   },
   "outputs": [],
   "source": [
    "def MSE(true_values, predicted_values):\n",
    "  \"\"\"Return the MSE between true_values and predicted values.\"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uF-x9DI2ZOKq"
   },
   "outputs": [],
   "source": [
    "print ('MSE for M1:', MSE(Y, M1))\n",
    "print ('MSE for M2:', MSE(Y, M2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDiy3OZwZlwj"
   },
   "source": [
    "## Generalization\n",
    "\n",
    "Our data $(X, Y)$ represents just a sample of all possible input-output pairs we might care about. A model will be useful to the extent we can apply it to new inputs. Consider the more complex model below, which appears to produce a much smaller mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ns1siZ9DZvSY"
   },
   "outputs": [],
   "source": [
    "# Fit an 8-th degree polynomial to (X, Y). See np.polyfit for details.\n",
    "polynomial_model_coefficients = np.polyfit(X, Y, deg=8)\n",
    "polynomial_model = np.poly1d(polynomial_model_coefficients)\n",
    "M3 = polynomial_model(X)\n",
    "fig = plt.scatter(X, Y)\n",
    "plt.plot(X, M3, '-k')\n",
    "print ('MSE for M3:', MSE(Y, M3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2m9YmLMZ1EV"
   },
   "source": [
    "---\n",
    "### Exercise 4: Generalization (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain whether you expect $M_3$ to be better than $M_2$ at predicting the labels for new unseen inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0Zpx79_aQEC"
   },
   "source": [
    "*Writen answer:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9EH9D7Faf9n"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hIdZHngdrET"
   },
   "source": [
    "## Review\n",
    "\n",
    "* In **Supervised Machine Learning**, we must start with data in the form $(X,Y)$ where $X$ are the inputs and $Y$ are the output labels.\n",
    "* A **model** is a function that maps an input $x$ to an output $y$. The model's output is referred to as a **prediction**, denoted by $\\hat{y}$.\n",
    "* We **evaluate** predictions by comparing them to the true labels. This measurement is called a **loss** or **error**. For real-valued data, **mean squared error** is a common metric.\n",
    "* A model is only as good as its ability to **generalize** to new examples."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "copyright",
    "xxOhpvdW6TbX",
    "exercise-1-key-1",
    "43ZTSJEc526U",
    "exercise-5-key-1",
    "ubHispCAA_5u",
    "exercise-6-key-1",
    "5p1IvWjfEjqm",
    "exercise-9-key-1"
   ],
   "name": "01 Introduction.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
